import pandas as pd
import numpy as np
from scipy.io import loadmat
import os

def fix_wrong_shank_NP2(cluster_info, ChanMap):
    """This function fixes wrong shank assignement in cluster_info. Relevant for NP2.0

    Args:
        cluster_info (str): path to folder that contains cluster_info.tsv file. 
                             Generated by Jennifer Colonell script for ephys analysis
        ChanMap (str): path to kilosort channel map. Requires running SGLXMetaToCoords.py from: 
                        https://github.com/jenniferColonell/ecephys_spike_sorting/blob/master/ecephys_spike_sorting/common/SGLXMetaToCoords.py
    """
    tmp = pd.read_csv(os.path.join(cluster_info, r"cluster_info.csv"), index_col="id")#, sep="/t")
    obj = loadmat(ChanMap)

    #Create temporary df to store shank and channel info, -1 needed to address matlab 1 based indexing
    channels =  np.concatenate(obj["chanMap"]).astype(int) - 1
    shanks = np.concatenate(obj["kcoords"]).astype(int) - 1

    df = pd.DataFrame(data={"channels": channels, "shanks": shanks})
    df = df.set_index("channels")

    #Change bad shank assignement to nan and replace with correct
    tmp["sh"] = np.nan
    tmp["sh"] = tmp["sh"].fillna(df["shanks"]) # I'm not sure how 'fillna' works - are you sure shank numbers are assigned correctly if: 
    # a) multiple units are recorded from same channel
    # b) no units are recorded from many channels?

    tmp.to_csv(os.path.join(cluster_info, r"cluster_info.csv")  )  # Probably bad idea to overwrite this file if someone doesn't store a copy elsewhere

def get_brain_regions(cluster_info, histology, neuropixels_20=True):
    """Adds a column to cluster_info with structure names from herbs matched to good units based on depth

    Args:
        cluster_info (str): path to folder that contains cluster_info.tsv file. 
                             Generated by Jennifer Colonell script for ephys analysis
        histology (str): path to folder containing herbs probe X.pkl files
        neuropixels_version (bool): default True, neuropixels version. Toggles NP shanks number (1 for 1.0, 4 for 2.0)
    """    

    tmp = pd.read_csv(os.path.join(cluster_info, r"cluster_info.csv"))
    good_rows = tmp.query("group == 'good'").copy()

    if neuropixels_20 == True:
        shanks = range(4)
    else:
        shanks = range(1)

    all_shanks = []

    for shank in shanks:
        obj = pd.read_pickle(histology + f"\\probe {shank}.pkl")
        keys = pd.Series(obj["data"]["region_label"]).unique()
        values = pd.Series(obj["data"]["label_name"]).unique()

        areas = {keys[i]: values[i] for i in range(len(keys))}
        
        temporary = pd.Series(np.append(obj["data"]["sites_label"][0], obj["data"]["sites_label"][1]))
        # So in HERBS output for NP.1 the obj["data"]["sites_label"] has only 2 columns, not 4? If yes, then the code is correct
        region_label_per_row = []
        for key in keys:
            a = temporary.loc[temporary == key]  # at some point if you use only generic variable names it becomes really hard to follow
            region_label_per_row.append(a)
        region_label_per_row = pd.concat(region_label_per_row, ignore_index=True)
        if neuropixels_20 == True:
            #15 um is the distance between NP2.0 contacts, 20um for NP1.0
            if (len(region_label_per_row) % 2) == 0:
                row_depth = np.arange(0, (obj["data"]["sites_label"][0].shape[0]*2)*15, 15) 
            else:
                row_depth = np.arange(0, (obj["data"]["sites_label"][0].shape[0]*2)*15+1, 15)
        else:
            if (len(region_label_per_row) % 2) == 0:
                row_depth = np.arange(0, (obj["data"]["sites_label"][0].shape[0]*2)*20, 20)
            else:
                row_depth = np.arange(0, (obj["data"]["sites_label"][0].shape[0]*2)*20+1, 20)
        area_name = region_label_per_row.map(areas)

        df = pd.DataFrame(data={"depth": row_depth, "Structure":area_name})
        
        #Add "Structure" column to good_rows for comparison
        temp = good_rows.query("sh == @shank").copy()
        temp["Structure"] = np.nan
        temp = temp.set_index("depth")
        df = df.set_index("depth")
        temp["Structure"] = temp["Structure"].fillna(df["Structure"])
        if neuropixels_20 == True:
            all_shanks.append(temp)
        else:
            temp = (temp.set_index(temp["id"])
                    .sort_index()
                    .drop(columns=["id"]))
            temp.to_csv(os.path.join(cluster_info, r"cluster_info_good.csv"))
    if neuropixels_20 == True:
        output = pd.concat(all_shanks)
        output = (output.reset_index()
                  .set_index(output["id"])
                  .sort_index()
                  .drop(columns=["id"]))
        output.to_csv(os.path.join(cluster_info, r"cluster_info_good.csv"))

def neurons_per_structure(all_good_clusters, save_path, plot=True):
    """Summary of a number of neurons recorded from each structure

    Args:
        all_good_clusters (list): list of all folder paths that contain cluster_info_good.csv files
        save_path (str): path to a folder
        plot (bool): default True, plots simple bar plot summarizing neurons per structure

    """    
    per_structure = []
    for good_cluster in all_good_clusters:
        path = os.path.join(good_cluster, "cluster_info_good.csv")
        df = pd.read_csv(path, index_col="id")
        all_neurons = pd.DataFrame(df["Structure"].value_counts())
        per_structure.append(all_neurons)
    output = pd.concat(per_structure, axis=1).sum(axis=1).astype(int)
    output.to_csv(os.path.join(save_path, "summary_per_structure.csv"), header=False)
    if plot == True:
        plot = output.plot(kind="bar", title="Summary", ylabel="neurons")
        fig = plot.get_figure()
        fig.autofmt_xdate()
        fig.savefig(os.path.join(save_path, "summary_per_structure.png"))
        fig.clf()

def neurons_per_behavior(all_good_clusters, behaviors, save_path, plotting=True):
    """Summary of a number of neurons per animal, behavior in a csv, creates csv for each structure

    !!!For now requires manually updating which neurons responded to which behavior in a column of 0/1 per id - 
    needs new function to automate!!!

    Args:
        all_good_clusters (list): list of all folder paths that contain cluster_info_good.csv files
        behaviors (list): list of strings containing behavior names
        save_path (str): path to a folder
        plot (bool): default True, if True creates simple bar plots per strucutre, x axis are behaviors, y axis are neurons

    """    
    for cluster in all_good_clusters:
        idx = cluster.split("\\")[-1].split("_")[0]
        df = pd.read_csv(os.path.join(cluster, "cluster_info_good.csv"), index_col="id")
        structures = df["Structure"].unique()
        for structure in structures:
            neurons = pd.DataFrame(index = [idx], columns = behaviors)
            for behavior in behaviors:
                neuron = len(df[(df[behavior] == 1) & (df["Structure"] == structure)])
                neurons[behavior][idx] = neuron
            filepath = os.path.join(save_path, f"{structure}.csv")
            if os.path.exists(filepath):
                neurons.to_csv(filepath, mode="a", index=True, header=False)
            else:
                neurons.to_csv(filepath)

    if plotting == True:
        files = glob(save_path + "\\*.csv")
        for file in files:
            temp = pd.read_csv(file)
            name = file.split("\\")[-1].split(".")[0]
            a = list(behaviors)
            neurons_plot = temp[a].sum(axis=0).plot(kind="bar", title=name, ylabel="neurons")
            fig = neurons_plot.get_figure()
            fig.autofmt_xdate()
            filename = file.split(".")[0] + ".png"
            fig.savefig(filename)
            fig.clf()
